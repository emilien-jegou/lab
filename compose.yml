services:
  orchestrator:
    image: oven/bun:latest
    container_name: orchestrator
    working_dir: /app
    ports:
      - "6601:8108"
    expose:
     - 8108
    volumes:
      - ./orchestrator/:/app
    command: bash -c "bun run watch"
    environment:
      - NODE_ENV=development
      - FORCE_COLOR=1

  auth:
    build:
      context: ./auth
      dockerfile: Dockerfile
    env_file: env/auth.env
    labels:
      - "com.centurylinklabs.watchtower.enable=false"
    restart: unless-stopped

  baserow:
    image: baserow/baserow:1.33.2
    container_name: baserow
    env_file: env/baserow.env
    environment:
      BASEROW_PUBLIC_URL: 'http://baserow:80'
    ports:
      - "80:80"
    volumes:
      - baserow_data:/baserow/data

  db:
    image: pgvector/pgvector:pg15
    env_file: env/db.env
    healthcheck:
      interval: 30s
      retries: 5
      start_period: 20s
      test: ["CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}"]
      timeout: 5s
    restart: unless-stopped
    volumes:
      - db_data:/var/lib/postgresql/data
    depends_on:
      - watchtower

  docling:
    image: quay.io/docling-project/docling-serve:latest
    env_file: env/docling.env
    healthcheck:
      interval: 30s
      retries: 5
      start_period: 10s
      test: curl --fail http://localhost:5001/health || exit 1
      timeout: 5s
    ports:
      - 5001:5001
    restart: unless-stopped

  openwebui:
    image: ghcr.io/open-webui/open-webui:cuda
    env_file: env/openwebui.env
    ports:
      - 6600:8080
    healthcheck:
      interval: 30s
      retries: 5
      start_period: 10s
      test: curl --fail http://localhost:8080/health || exit 1
      timeout: 3s
    restart: unless-stopped
    volumes:
      - openwebui:/app/backend/data
    depends_on:
      - auth
      - docling
      - db
      - ollama
      - searxng
      - tika
      - watchtower

  redis:
    image: redis/redis-stack:latest
    env_file: env/redis.env
    healthcheck:
      interval: 30s
      retries: 5
      start_period: 20s
      test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
      timeout: 3s
    ports:
      - 6379:6379
    restart: unless-stopped
    volumes:
      - redis:/data
    depends_on:
      - watchtower

  searxng:
    image: searxng/searxng:latest
    env_file: env/searxng.env
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    cap_drop:
      - ALL
    depends_on:
      - redis
      - watchtower
    healthcheck:
      interval: 30s
      retries: 5
      start_period: 10s
      test: curl --fail http://localhost:8080/ || exit 1
      timeout: 3s
    ports:
      - 6605:8080
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"
    restart: unless-stopped
    volumes:
      - ./conf/searxng/settings.yml:/etc/searxng/settings.yml:rw
      - ./conf/searxng/uwsgi.ini:/etc/searxng/uwsgi.ini:rw

  tika:
    image: apache/tika:latest-full
    env_file: env/tika.env
    healthcheck:
      interval: 30s
      retries: 5
      start_period: 5s
      test: curl --fail http://localhost:9998/tika || exit 1
      timeout: 5s
    ports:
      - 9998:9998
    restart: unless-stopped

  watchtower:
    image: containrrr/watchtower
    env_file: env/watchtower.env
    command: --cleanup --debug --interval 300
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  comfyui:
    image: yanwk/comfyui-boot:cu124-slim
    env_file: env/comfyui.env
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      - watchtower
    deploy:
      replicas: 0
    ports:
      - 6604:8188
    restart: unless-stopped
    volumes:
      - comfyui:/root/ComfyUI
      - ./conf/comfyui/download-models.txt:/runner-scripts/download-models.txt

  ollama:
    depends_on:
      - watchtower
    env_file: env/ollama.env
    devices:
      - "nvidia.com/gpu=all"
    healthcheck:
      interval: 30s
      retries: 5
      start_period: 10s
      test: curl --fail http://localhost:11434/api/version || exit 1
      timeout: 3s
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    restart: unless-stopped
    volumes:
      - ollama:/root/.ollama

  crawl4ai:
    image: unclecode/crawl4ai:latest
    container_name: crawl4ai
    ports:
      - "6603:11235"
    shm_size: "1g"
    env_file: env/crawl4ai.env
    volumes:
      - /dev/shm:/dev/shm  # Chromium performance
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11235/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    user: "appuser"

volumes:
  baserow_data: null
  db_data: null
  openwebui: null
  redis: null
  comfyui: null
  ollama: null
